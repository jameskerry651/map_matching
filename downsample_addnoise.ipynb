{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:53.089650Z",
     "start_time": "2025-07-15T08:01:53.087558Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:53.148911Z",
     "start_time": "2025-07-15T08:01:53.146002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def downsample_gps_by_order(df: pd.DataFrame, rule: str = '1T') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对GPS轨迹数据按订单进行时间降采样。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 包含GPS数据的DataFrame，\n",
    "                           必须包含 ['order_id', 'gps_time', 'longitude', 'latitude'] 字段。\n",
    "                           'driver_id' 字段也会被保留。\n",
    "        rule (str, optional): 降采样的时间频率规则。\n",
    "                              默认为 '1T' (即 '1min'，每分钟采样一次)。\n",
    "                              常用规则: '5S' (5秒), '10T' (10分钟), 'H' (每小时)。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 降采样后的新DataFrame。\n",
    "    \"\"\"\n",
    "    # 0. 复制DataFrame以避免修改原始数据\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # 1. 确保 'gps_time' 是 datetime 类型，这是进行时间操作的前提\n",
    "    # to_datetime 会自动尝试解析多种格式，包括Unix时间戳（如果指定单位）\n",
    "    if not np.issubdtype(df_copy['gps_time'].dtype, np.datetime64):\n",
    "        df_copy['gps_time'] = pd.to_datetime(df_copy['gps_time'])\n",
    "\n",
    "    # 2. 将 'gps_time' 设置为索引，以便使用 resample\n",
    "    df_copy = df_copy.set_index('gps_time')\n",
    "\n",
    "    # 3. 创建一个列表来存储每个订单降采样后的结果\n",
    "    resampled_dfs = []\n",
    "\n",
    "    # 4. 按 'order_id' 分组并对每个组进行操作\n",
    "    for order_id, group in df_copy.groupby('order_id'):\n",
    "        # 对每个订单的DataFrame进行降采样\n",
    "        # .resample(rule) 创建时间窗口\n",
    "        # .first() 在每个窗口中取第一条记录\n",
    "        # 这会保留 driver_id, longitude, latitude 等字段的第一个值\n",
    "        resampled_group = group.resample(rule).first()\n",
    "\n",
    "        # .resample() 可能会产生所有列都为NaN的空行（如果某个时间窗口内没有数据）\n",
    "        # 我们使用 dropna() 清除这些完全为空的行\n",
    "        resampled_group = resampled_group.dropna(how='all')\n",
    "\n",
    "        # 将 order_id 加回到列中，因为它在groupby后变成了组的名称\n",
    "        resampled_group['order_id'] = order_id\n",
    "\n",
    "        resampled_dfs.append(resampled_group)\n",
    "\n",
    "    # 5. 将所有处理过的组重新合并成一个DataFrame\n",
    "    if not resampled_dfs:\n",
    "        # 如果输入为空或结果为空，返回一个结构相同的空DataFrame\n",
    "        return pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    final_df = pd.concat(resampled_dfs)\n",
    "\n",
    "    # 6. 重置索引，将 'gps_time' 从索引变回普通列\n",
    "    final_df = final_df.reset_index()\n",
    "\n",
    "    # 7. 重新排列列的顺序，与输入保持一致\n",
    "    # 使用 [col for col in df.columns if col in final_df.columns] 来确保列存在\n",
    "    final_df = final_df[df.columns]\n",
    "\n",
    "    return final_df"
   ],
   "id": "90dc416b323e771c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:53.348258Z",
     "start_time": "2025-07-15T08:01:53.157519Z"
    }
   },
   "cell_type": "code",
   "source": "original_df = pd.read_csv('filtered_orders.csv')",
   "id": "a03703e8fe02af58",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:56.987213Z",
     "start_time": "2025-07-15T08:01:53.357557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# '1T' 或 '1min' 代表1分钟\n",
    "# ‘5S’ 代表5秒钟\n",
    "downsampled_df = downsample_gps_by_order(original_df, rule='20s')\n",
    "print(downsampled_df)\n",
    "print(f\"\\n降采样后数据行数: {len(downsampled_df)}\")\n",
    "\n",
    "downsampled_df.to_csv('filtered_downsample.csv', index=False)"
   ],
   "id": "9cd2e85ce19af0a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              driver_id                          order_id  \\\n",
      "0      9a9ac4db0843220095674816bcbe28d7  000a7cb982caa7c3a7b0245b6fd3da08   \n",
      "1      9a9ac4db0843220095674816bcbe28d7  000a7cb982caa7c3a7b0245b6fd3da08   \n",
      "2      9a9ac4db0843220095674816bcbe28d7  000a7cb982caa7c3a7b0245b6fd3da08   \n",
      "3      9a9ac4db0843220095674816bcbe28d7  000a7cb982caa7c3a7b0245b6fd3da08   \n",
      "4      9a9ac4db0843220095674816bcbe28d7  000a7cb982caa7c3a7b0245b6fd3da08   \n",
      "...                                 ...                               ...   \n",
      "57780  2eb4c952f0af747168f11dd229936342  fff0ee2db1bd1cd98ce4c49cb0cd4851   \n",
      "57781  2eb4c952f0af747168f11dd229936342  fff0ee2db1bd1cd98ce4c49cb0cd4851   \n",
      "57782  2eb4c952f0af747168f11dd229936342  fff0ee2db1bd1cd98ce4c49cb0cd4851   \n",
      "57783  2eb4c952f0af747168f11dd229936342  fff0ee2db1bd1cd98ce4c49cb0cd4851   \n",
      "57784  2eb4c952f0af747168f11dd229936342  fff0ee2db1bd1cd98ce4c49cb0cd4851   \n",
      "\n",
      "                 gps_time   longitude   latitude  time_diff  \n",
      "0     2016-11-01 10:55:00  104.066005  30.721559        9.0  \n",
      "1     2016-11-01 10:55:20  104.066025  30.721689        3.0  \n",
      "2     2016-11-01 10:55:40  104.066234  30.723218        3.0  \n",
      "3     2016-11-01 10:56:00  104.067023  30.724567        3.0  \n",
      "4     2016-11-01 10:56:20  104.068001  30.726305        3.0  \n",
      "...                   ...         ...        ...        ...  \n",
      "57780 2016-11-01 14:57:00  104.061715  30.660654        3.0  \n",
      "57781 2016-11-01 14:57:20  104.061765  30.659134        3.0  \n",
      "57782 2016-11-01 14:57:40  104.062863  30.658793        3.0  \n",
      "57783 2016-11-01 14:58:00  104.063303  30.657153        3.0  \n",
      "57784 2016-11-01 14:58:20  104.063353  30.656113        3.0  \n",
      "\n",
      "[57785 rows x 6 columns]\n",
      "\n",
      "降采样后数据行数: 57785\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:06:00.958960Z",
     "start_time": "2025-07-15T08:06:00.954089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_gps_noise(df: pd.DataFrame, noise_level_meters: float = 10.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    为DataFrame中的GPS坐标点添加高斯噪声。\n",
    "\n",
    "    该函数会创建新的 'longitude_noisy' 和 'latitude_noisy' 列。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 包含GPS数据的DataFrame，\n",
    "                           必须包含 ['longitude', 'latitude'] 字段。\n",
    "        noise_level_meters (float, optional): 噪声的标准差，以米为单位。\n",
    "                                              默认为 10.0。这个值越大，噪声点越离散。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 带有噪声GPS坐标的新列的DataFrame。\n",
    "    \"\"\"\n",
    "    # 0. 复制DataFrame以避免修改原始数据\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # 1. 定义米和度之间的转换常数\n",
    "    METERS_PER_DEGREE_LAT = 111132.0  # 全局近似值\n",
    "\n",
    "    # 2. 生成高斯噪声（均值为0，标准差为1）\n",
    "    # 我们为经度和纬度分别生成与DataFrame行数相同的随机数\n",
    "    num_rows = len(df_copy)\n",
    "    # loc=0.0 (均值), scale=1.0 (标准差), size=num_rows (数量)\n",
    "    random_gaussian = np.random.normal(0.0, 1.0, size=(num_rows, 2))\n",
    "\n",
    "    # 3. 将噪声从米转换为度\n",
    "    # 纬度噪声（单位：度）\n",
    "    lat_noise = (random_gaussian[:, 0] * noise_level_meters) / METERS_PER_DEGREE_LAT\n",
    "\n",
    "    # 经度噪声（单位：度）\n",
    "    # 经度的转换依赖于纬度，我们使用向量化操作来为每一行计算其对应的转换因子\n",
    "    # np.cos() 需要弧度，所以先用 np.radians() 转换\n",
    "    meters_per_degree_lon = 111320.0 * np.cos(np.radians(df_copy['latitude']))\n",
    "    lon_noise = (random_gaussian[:, 1] * noise_level_meters) / meters_per_degree_lon\n",
    "\n",
    "    # 4. 将噪声添加到原始坐标上，创建新列\n",
    "    df_copy['longitude'] = df_copy['longitude'] + lon_noise\n",
    "    df_copy['latitude'] = df_copy['latitude'] + lat_noise\n",
    "\n",
    "    return df_copy"
   ],
   "id": "dffd7eab3ec0c91f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:06:58.504619Z",
     "start_time": "2025-07-15T08:06:58.230748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_with_noise = add_gps_noise(downsampled_df, noise_level_meters=50)\n",
    "\n",
    "df_with_noise.to_csv('filtered_with_noise.csv', index=False)"
   ],
   "id": "ddecfe0a4d9f6969",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
